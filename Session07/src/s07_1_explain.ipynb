{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a></a>"]},{"cell_type":"code","source":[],"metadata":{"id":"hHNUINTD3iKT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Objective: Model Explanation with\n","1. IG\n","2. IG w/ Noise Tunnel\n","3. Saliency\n","4. Occlusion\n","5. SHAP\n","6. GradCAM\n","7. GradCAM++"],"metadata":{"id":"ZxG8x2R3DzJn"}},{"cell_type":"code","source":[],"metadata":{"id":"QDC4mO7D3nZ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","gdrivepath=\"/content/gdrive/My Drive/EMLO2/S07_Main/\"\n","import os \n","os.chdir(gdrivepath)\n","!pwd\n","!ls"],"metadata":{"id":"gHaL9FWERI-I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669898515741,"user_tz":-330,"elapsed":42326,"user":{"displayName":"Jaideep R","userId":"05457039333441489486"}},"outputId":"4345d767-49d2-44ad-f325-e1d0d70777a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/EMLO2/S07_Main\n","explain.py\t      s07_1_explain.ipynb\n","imagenet_classes.txt  s07_2_explain_Adveserial_Attacks.ipynb\n","images\t\t      s07_3_robustness.ipynb\n","output\t\t      setup.py\n","requirements.txt\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxkxZ8hAVxMG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669898568182,"user_tz":-330,"elapsed":18401,"user":{"displayName":"Jaideep R","userId":"05457039333441489486"}},"outputId":"d8d59646-a488-45fd-93ef-347b77e51893"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.4 MB 38.9 MB/s \n","\u001b[K     |████████████████████████████████| 549 kB 61.4 MB/s \n","\u001b[K     |████████████████████████████████| 575 kB 82.2 MB/s \n","\u001b[K     |████████████████████████████████| 7.8 MB 33.3 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 182 kB 83.9 MB/s \n","\u001b[?25h  Building wheel for grad-cam (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["%pip install captum timm shap grad-cam --quiet"]},{"cell_type":"code","source":["import timm\n","import urllib\n","import torch\n","\n","import numpy as np\n","\n","import torchvision.transforms as T\n","import torch.nn.functional as F\n","\n","from PIL import Image\n","\n","from matplotlib.colors import LinearSegmentedColormap\n","\n","import matplotlib.pyplot as plt"],"metadata":{"id":"79ctcu1aWXK2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os"],"metadata":{"id":"GL4G6Xjaw9-R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\")\n","#device = torch.device(\"cpu\")"],"metadata":{"id":"0q5zL0ekWayj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download human-readable labels for ImageNet.\n","# get the classnames\n","url, filename = (\n","    \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\",\n","    \"imagenet_classes.txt\",\n",")\n","urllib.request.urlretrieve(url, filename)\n","with open(\"imagenet_classes.txt\", \"r\") as f:\n","    categories = [s.strip() for s in f.readlines()]\n"],"metadata":{"id":"1X3uGkJ4lLeE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Resnet-18\n"],"metadata":{"id":"WKQJ5gapXftq"}},{"cell_type":"code","source":["model = timm.create_model(\"resnet18\", pretrained=True) \n","model.eval()\n","model = model.to(device)"],"metadata":{"id":"a4Ud9Hqw3zFw","executionInfo":{"status":"ok","timestamp":1669898629530,"user_tz":-330,"elapsed":5194,"user":{"displayName":"Jaideep R","userId":"05457039333441489486"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"227c3d13-cb89-4e2f-fda3-d53dbb69e382"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"]}]},{"cell_type":"code","source":["transform = T.Compose([\n","    # T.Resize((299, 299)),\n","    T.Resize((224, 224)),\n","    # T.Resize((384, 384)),\n","    # T.CenterCrop(224),\n","    T.ToTensor()\n","])\n","\n","mean = [0.485, 0.456, 0.406]\n","std  = [0.229, 0.224, 0.225]\n","\n","transform_normalize = T.Normalize(\n","     mean=mean,\n","     std=std\n",")\n","inv_transform= T.Compose([\n","    T.Normalize(\n","        mean = (-1 * np.array(mean) / np.array(std)).tolist(),\n","        std = (1 / np.array(std)).tolist()\n","    ),\n","])\n"],"metadata":{"id":"GbidcVPwXqii"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from captum.attr import IntegratedGradients\n","from captum.attr import GradientShap\n","from captum.attr import Occlusion\n","from captum.attr import NoiseTunnel\n","from captum.attr import Saliency\n","from captum.attr import visualization as viz"],"metadata":{"id":"3cJmYFxTm9zx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pytorch_grad_cam import GradCAM, GradCAMPlusPlus, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n","from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n","from pytorch_grad_cam.utils.image import show_cam_on_image"],"metadata":{"id":"42pRXjnBHd3M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define a color map for black to white"],"metadata":{"id":"DNFBYhIPDdZV"}},{"cell_type":"code","source":["default_cmap = LinearSegmentedColormap.from_list('custom blue', \n","                                                 [(0, '#ffffff'),\n","                                                  (0.25, '#000000'),\n","                                                  (1, '#000000')], N=256)"],"metadata":{"id":"TaKuBxlnomHH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["explainability_methods = ['ig', 'nt', 'grad_shap', 'saliency', 'occ', 'gcp', 'gc']"],"metadata":{"id":"IAfus_TDwKIT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def grad_cam(img_tensor, plus=False):\n","    target_layers = [model.layer4[-1]]\n","    targets = [ClassifierOutputTarget(281)]\n","\n","    if plus:\n","        cam = GradCAMPlusPlus(model=model, target_layers=target_layers, use_cuda=True)\n","    else:\n","        cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)\n","    \n","    # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n","    grayscale_cam = cam(input_tensor=img_tensor, targets=targets)\n","    # In this example grayscale_cam has only one image in the batch:\n","    grayscale_cam = grayscale_cam[0, :]\n","    rgb_img = inv_transform(img_tensor).cpu().squeeze().permute(1, 2, 0).detach().numpy()\n","    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n","    plt.imshow(visualization)\n","    return(visualization)"],"metadata":{"id":"NfHqrQxmHOlv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def explainable_out(img_path, method='ig'):\n","    #out_img_path = img_path[:img_path.rfind(\".\")] + \"_\" + method + \".jpg\"\n","\n","    path_list = img_path.split(os.sep)\n","    filname=path_list[1]\n","    #print (path_list)\n","    out_img_path = \"output_1/\"+filname[:filname.rfind(\".\")] + \"_\" + method + \".jpg\"\n","\n","\n","    #print(out_img_path)\n","    img = Image.open(img_path)\n","    transformed_img = transform(img)\n","    img_tensor = transform_normalize(transformed_img)\n","    img_tensor = img_tensor.unsqueeze(0)\n","\n","    img_tensor = img_tensor.to(device)\n","    output = model(img_tensor)\n","\n","    # output_sig = torch.sigmoid(output)\n","    output = F.softmax(output, dim=1)\n","    prediction_score, pred_label_idx = torch.topk(output, 1)\n","    pred_label_idx.squeeze_()\n","    predicted_label = categories[pred_label_idx.item()]\n","    print('Predicted:', predicted_label, '(', prediction_score.squeeze().item(), ')')\n","\n","    original_image = np.transpose((img_tensor.squeeze(0).cpu().detach().numpy() / 2) + 0.5, (1, 2, 0))\n","    print(\"*---------------------- \" + method + \" ----------------------*\" )\n","    if method == \"gc\":\n","        plt_fig = grad_cam(img_tensor)\n","        # plt_fig.savefig(out_img_path)\n","        return plt_fig\n","    if method == \"gcp\":\n","        plt_fig = grad_cam(img_tensor, True)\n","        # plt_fig.savefig(out_img_path)\n","        return plt_fig\n","\n","    heat_map_method = \"heat_map\"\n","    sign=\"positive\"\n","    cmap=default_cmap\n","\n","    if method == \"ig\":\n","        integrated_gradients = IntegratedGradients(model)\n","        attributions = integrated_gradients.attribute(img_tensor, target=pred_label_idx, n_steps=200)\n","\n","        del integrated_gradients\n","        \n","    if method == 'nt':\n","        print(\"Noise Tunnel\")\n","        integrated_gradients = IntegratedGradients(model)\n","        noise_tunnel = NoiseTunnel(integrated_gradients)\n","\n","        attributions = noise_tunnel.attribute(img_tensor, nt_samples=10, nt_type='smoothgrad_sq', target=pred_label_idx)\n","        del integrated_gradients\n","        del noise_tunnel\n","\n","    if method == 'grad_shap':\n","        torch.manual_seed(0)\n","        np.random.seed(0)\n","\n","        gradient_shap = GradientShap(model)\n","\n","        # Defining baseline distribution of images\n","        rand_img_dist = torch.cat([img_tensor * 0, img_tensor * 1])\n","\n","        attributions = gradient_shap.attribute(img_tensor,\n","                                                n_samples=50,\n","                                                stdevs=0.0001,\n","                                                baselines=rand_img_dist,\n","                                                target=pred_label_idx)\n","        del gradient_shap\n","        del rand_img_dist\n","\n","    if method == 'occ':\n","        occlusion = Occlusion(model)\n","        attributions = occlusion.attribute(img_tensor,\n","                                            strides = (3, 8, 8),\n","                                            target=pred_label_idx,\n","                                            sliding_window_shapes=(3,15, 15),\n","                                            baselines=0)\n","        heat_map_method = \"blended_heat_map\"\n","        sign=\"absolute_value\"\n","        cmap=None\n","        del occlusion\n","\n","    if method == 'saliency':\n","        saliency = Saliency(model)\n","        attributions = saliency.attribute(img_tensor, target=pred_label_idx)\n","        heat_map_method = \"blended_heat_map\"\n","        sign=\"absolute_value\"\n","        cmap=None\n","        del saliency\n","        \n","\n","    plt_fig, _ = viz.visualize_image_attr(np.transpose(attributions.squeeze().cpu().detach().numpy(), (1,2,0)),\n","                                 original_image, method=heat_map_method,\n","                                 cmap=cmap,\n","                                 sign=sign,\n","                        #   show_colorbar=True, title=\"Overlayed Gradient Magnitudes\"\n","                          )\n","   \n","    del attributions\n","    print(out_img_path)\n","    plt_fig.savefig(out_img_path)\n","    print(\"*---------------------------------------------------*\" )    \n","    return plt_fig"],"metadata":{"id":"QtcCRzZFqLWe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for img in os.listdir('images'):\n","    img_path = \"images/\"+img\n","    for meth in explainability_methods:\n","        explainable_out(img_path, meth)"],"metadata":{"id":"vI4Ku-jbxNAz","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1TrbeQJODx0gglMr3N1sJMaSUSe-pJdfq"},"outputId":"627c87a4-2c53-48af-b15b-cc5a0ff98dbe","executionInfo":{"status":"ok","timestamp":1669899997892,"user_tz":-330,"elapsed":77684,"user":{"displayName":"Jaideep R","userId":"05457039333441489486"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"-Gmv7rNB5H1i"},"execution_count":null,"outputs":[]}]}