# -*- coding: utf-8 -*-
"""s07_2_explain_Adveserial_Attacks.ipynb

Automatically generated by Colaboratory.

"""

# Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount("/content/gdrive", force_remount=True).
from google.colab import drive
drive.mount("/content/gdrive")
gdrivepath="/content/gdrive/My Drive/EMLO2/S07_Main/"
import os 
os.chdir(gdrivepath)
!pwd
!ls

# Commented out IPython magic to ensure Python compatibility.
# %pip install timm captum --quiet

import timm
import urllib
import torch

import numpy as np

import torchvision.transforms as T
import torch.nn.functional as F

from PIL import Image

from matplotlib.colors import LinearSegmentedColormap

import matplotlib.pyplot as plt

import os

from captum.robust import FGSM
from captum.robust import PGD

# device = torch.device("cuda")
device = torch.device("cpu")

# Download human-readable labels for ImageNet.
# get the classnames
url, filename = (
    "https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt",
    "imagenet_classes.txt",
)
urllib.request.urlretrieve(url, filename)
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

categories

cat_label = categories.index('Persian cat')

model = timm.create_model("resnet18", pretrained=True) #vgg11 #xception
model.eval()
model = model.to(device)

mean = [0.485, 0.456, 0.406]
std  = [0.229, 0.224, 0.225]

transform = T.Compose([
    T.Resize((224, 224)),
    T.ToTensor(),
    T.Normalize(
        mean=mean,
        std=std
    )
])

inv_transform= T.Compose([
    T.Normalize(
        mean = (-1 * np.array(mean) / np.array(std)).tolist(),
        std = (1 / np.array(std)).tolist()
    ),
])

print(gdrivepath)
os.chdir(gdrivepath)

img = Image.open('images/1-boat.jpg')

img_tensor = transform(img)
img_tensor = img_tensor.unsqueeze(0)
img_tensor.requires_grad = True
img_tensor = img_tensor.to(device)

def get_prediction(model, image: torch.Tensor):
    model = model.to(device)
    img_tensor = image.to(device)
    with torch.no_grad():
        output = model(img_tensor)
    output = F.softmax(output, dim=1)
    prediction_score, pred_label_idx = torch.topk(output, 1)

    pred_label_idx.squeeze_()
    predicted_label = categories[pred_label_idx.item()]

    return predicted_label, prediction_score.squeeze().item()

def image_show(img, pred):
    npimg = inv_transform(img).squeeze().permute(1, 2, 0).detach().numpy()
    plt.axis('off')
    plt.imshow(npimg)
    plt.title("prediction: %s" % pred)
    plt.show()

pgd = PGD(model, torch.nn.CrossEntropyLoss(reduction='none'), lower_bound=-1, upper_bound=1)  # construct the PGD attacker

pred, score  = get_prediction(model, img_tensor)
image_show(img_tensor, pred + " " + str(score))

perturbed_image_pgd = pgd.perturb(inputs=img_tensor, radius=0.13, step_size=0.02, 
                                  step_num=7, target=torch.tensor([cat_label]).to(device), targeted=True) 
new_pred_pgd, score_pgd = get_prediction(model, perturbed_image_pgd)

image_show(perturbed_image_pgd.cpu(), new_pred_pgd + " " + str(score_pgd))

def get_adveserial_image(img_path, new_pred_class):
    
    img = Image.open(img_path)

    img_tensor = transform(img)
    img_tensor = img_tensor.unsqueeze(0)
    img_tensor.requires_grad = True
    img_tensor = img_tensor.to(device)

    perturbed_image_pgd = pgd.perturb(inputs=img_tensor, radius=0.13, step_size=0.02, 
                                  step_num=7, target=torch.tensor([new_pred_class]).to(device), targeted=True) 
    new_pred_pgd, score_pgd = get_prediction(model, perturbed_image_pgd)
    
    image_show(perturbed_image_pgd.cpu(), new_pred_pgd + " " + str(score_pgd))

    return perturbed_image_pgd

for img_name in os.listdir('images'):
    img_path = "images/"+img_name
    #---------
    path_list = img_path.split(os.sep)
    filname=path_list[1]
    #print (path_list)
    print("*------------------------------------------*")
    out_img_path = "output_2/"+filname[:filname.rfind(".")] + "_adv" + ".jpg"
    print(out_img_path)
    
    # out_img_path = img_name[:img_name.rfind(".")] + "_adv" + ".jpg"
    
    adv_img = get_adveserial_image(img_path, cat_label)
    piltransform = T.ToPILImage()
    
    piltransform(inv_transform(adv_img).squeeze()).save(out_img_path)
    print("*------------------------------------------*")